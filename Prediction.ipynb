{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cee440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f87066a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = '/GPU:0' if len(tf.config.list_physical_devices('GPU')) > 0 else '/CPU:0'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db30718",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda7682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (55374, 24)\n"
     ]
    }
   ],
   "source": [
    "# load prediction data\n",
    "directory = 'data/'\n",
    "dataset_path = os.path.join(directory, 'prediction_dataset.csv')\n",
    "dataset_df = pd.read_csv(dataset_path)\n",
    "print(\"Shape:\", dataset_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe13271a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    atur kepala badan duduk keluarga rencana nasio...\n",
       "1    atur menteri uang nomor pmk tatacara hitung ba...\n",
       "2    atur menteri uang nomor pmk ubah ata atur ment...\n",
       "3    atur menteri uang nomor pmk kembali bea masuk ...\n",
       "4    atur menteri uang nomor pmk alokasi kurang bay...\n",
       "Name: judul_dokumen, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the text data to be predicted\n",
    "text_df = dataset_df['judul_dokumen']\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f277c",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ef8a6",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221ce3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indobert tokenizer instance\n",
    "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46047172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sentence:\n",
      " atur menteri hubung nomor pm tahun tata cara aju tuju rencana investasi usaha umum lembaga selenggara layan navigasi terbang indonesia\n",
      "Tokenized sentence:\n",
      " [2, 7194, 2690, 23789, 1288, 2419, 262, 2816, 354, 2116, 30360, 23641, 2596, 3077, 1062, 752, 2178, 157, 1005, 85, 933, 5, 14296, 5109, 300, 3]\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text\n",
    "text_sequences = text_df.apply(lambda sequence: tokenizer.encode(sequence))\n",
    "print(\"Real sentence:\\n\", text_df[12345])\n",
    "print(\"Tokenized sentence:\\n\", text_sequences[12345])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b49bc58",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c115f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# pad the text into the same length\n",
    "max_length = 100\n",
    "padded_sequences = pad_sequences(text_sequences, maxlen=max_length)\n",
    "print(\"Shape:\", padded_sequences[12345].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a772b6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296ac3d",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c237f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"kaidah_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 64)           1953344   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 54)                3510      \n",
      "=================================================================\n",
      "Total params: 1,956,854\n",
      "Trainable params: 1,956,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load keras saved model\n",
    "saved_model_path = 'simple_kaidah_model.h5'\n",
    "model = tf.keras.models.load_model(saved_model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6ba4e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b81479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from text\n",
    "predictions = model.predict(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "052f10fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12235361, 0.11918838, 0.13036887, 0.11352316, 0.11331199,\n",
       "       0.14487611, 0.11495935, 0.10588241, 0.10497704, 0.09917248,\n",
       "       0.13381623, 0.12376384, 0.10592593, 0.10646056, 0.1451548 ,\n",
       "       0.12206271, 0.11736595, 0.11643667, 0.09956431, 0.09232514,\n",
       "       0.11091688, 0.14629649, 0.11876089, 0.12659644, 0.11393417,\n",
       "       0.1308963 , 0.1530765 , 0.09712965, 0.11423308, 0.11072848,\n",
       "       0.09749048, 0.09977307, 0.13663243, 0.10286006, 0.1289975 ,\n",
       "       0.13436511, 0.12042274, 0.10650082, 0.10002356, 0.13518551,\n",
       "       0.12282439, 0.12096839, 0.16307774, 0.10923144, 0.12998466,\n",
       "       0.11269809, 0.10365465, 0.11710158, 0.11226106, 0.10180741,\n",
       "       0.08857999, 0.14915283, 0.11853752, 0.8789374 ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[55373]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e788c78b",
   "metadata": {},
   "source": [
    "0.8957185 0.89517206 0.8943941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d7fd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, prediction in enumerate(predictions):\n",
    "    if prediction.argmax() != 53:\n",
    "        print(index, prediction.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e93b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
